{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purchase Value Prediction - Data Exploration\n",
    "\n",
    "This notebook provides exploratory data analysis for the purchase value prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('../data/raw/train_data.csv')\n",
    "test_df = pd.read_csv('../data/raw/test_data.csv')\n",
    "sample_submission = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Training Data Info:\")\n",
    "train_df.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"First few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable statistics\n",
    "target = train_df['purchaseValue']\n",
    "\n",
    "print(\"Purchase Value Statistics:\")\n",
    "print(target.describe())\n",
    "print(f\"\\nZeros: {(target == 0).sum()} ({(target == 0).mean()*100:.1f}%)\")\n",
    "print(f\"Non-zeros: {(target > 0).sum()} ({(target > 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Full distribution\n",
    "axes[0, 0].hist(target, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Purchase Value Distribution (Full)')\n",
    "axes[0, 0].set_xlabel('Purchase Value')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Log scale (for non-zero values)\n",
    "non_zero_target = target[target > 0]\n",
    "if len(non_zero_target) > 0:\n",
    "    axes[0, 1].hist(np.log1p(non_zero_target), bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].set_title('Purchase Value Distribution (Log Scale, Non-Zero)')\n",
    "    axes[0, 1].set_xlabel('Log(Purchase Value + 1)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[1, 0].boxplot(target, vert=True)\n",
    "axes[1, 0].set_title('Purchase Value Box Plot')\n",
    "axes[1, 0].set_ylabel('Purchase Value')\n",
    "\n",
    "# Box plot (non-zero only)\n",
    "if len(non_zero_target) > 0:\n",
    "    axes[1, 1].boxplot(non_zero_target, vert=True)\n",
    "    axes[1, 1].set_title('Purchase Value Box Plot (Non-Zero)')\n",
    "    axes[1, 1].set_ylabel('Purchase Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_train = train_df.isnull().sum().sort_values(ascending=False)\n",
    "missing_test = test_df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Missing Values in Training Data:\")\n",
    "print(missing_train[missing_train > 0])\n",
    "print(f\"\\nTotal missing values: {missing_train.sum()}\")\n",
    "\n",
    "print(\"\\nMissing Values in Test Data:\")\n",
    "print(missing_test[missing_test > 0])\n",
    "print(f\"\\nTotal missing values: {missing_test.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Types Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature types\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if 'purchaseValue' in numeric_cols:\n",
    "    numeric_cols.remove('purchaseValue')\n",
    "\n",
    "print(f\"Numeric columns ({len(numeric_cols)}):\")\n",
    "for col in numeric_cols[:10]:  # Show first 10\n",
    "    print(f\"  - {col}\")\n",
    "if len(numeric_cols) > 10:\n",
    "    print(f\"  ... and {len(numeric_cols)-10} more\")\n",
    "\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols[:10]:  # Show first 10\n",
    "    unique_count = train_df[col].nunique()\n",
    "    print(f\"  - {col} ({unique_count} unique values)\")\n",
    "if len(categorical_cols) > 10:\n",
    "    print(f\"  ... and {len(categorical_cols)-10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze some key categorical features\n",
    "key_categorical = ['browser', 'deviceType', 'userChannel', 'locationCountry']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(key_categorical):\n",
    "    if col in train_df.columns:\n",
    "        value_counts = train_df[col].value_counts().head(10)\n",
    "        value_counts.plot(kind='bar', ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Distribution (Top 10)')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Numeric Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze some key numeric features\n",
    "key_numeric = ['pageViews', 'totalHits', 'sessionNumber', 'totals.visits']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(key_numeric):\n",
    "    if col in train_df.columns:\n",
    "        # Remove extreme outliers for better visualization\n",
    "        data = train_df[col].dropna()\n",
    "        q99 = data.quantile(0.99)\n",
    "        data_clipped = data[data <= q99]\n",
    "        \n",
    "        axes[i].hist(data_clipped, bins=30, alpha=0.7, edgecolor='black')\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Purchase Value by Key Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze purchase value by key categorical variables\n",
    "categorical_analysis = ['userChannel', 'deviceType', 'browser']\n",
    "\n",
    "fig, axes = plt.subplots(len(categorical_analysis), 1, figsize=(12, 4*len(categorical_analysis)))\n",
    "if len(categorical_analysis) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, col in enumerate(categorical_analysis):\n",
    "    if col in train_df.columns:\n",
    "        # Group by category and calculate mean purchase value\n",
    "        grouped = train_df.groupby(col)['purchaseValue'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "        \n",
    "        # Only show categories with at least 100 samples\n",
    "        grouped_filtered = grouped[grouped['count'] >= 100].head(10)\n",
    "        \n",
    "        if len(grouped_filtered) > 0:\n",
    "            grouped_filtered['mean'].plot(kind='bar', ax=axes[i])\n",
    "            axes[i].set_title(f'Average Purchase Value by {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Average Purchase Value')\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numeric features\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = train_df[numeric_features].corr()\n",
    "\n",
    "# Plot correlation with target variable\n",
    "target_corr = correlation_matrix['purchaseValue'].drop('purchaseValue').sort_values(key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "target_corr.head(20).plot(kind='barh')\n",
    "plt.title('Top 20 Features - Correlation with Purchase Value')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Correlated Features with Purchase Value:\")\n",
    "print(target_corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATASET SUMMARY ===\")\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Test samples: {len(test_df):,}\")\n",
    "print(f\"Total features: {len(train_df.columns)-1}\")\n",
    "print(f\"Numeric features: {len(numeric_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "print(f\"Missing values: {train_df.isnull().sum().sum():,}\")\n",
    "print(f\"Target variable range: {train_df['purchaseValue'].min():.2f} - {train_df['purchaseValue'].max():.2f}\")\n",
    "print(f\"Zero purchase values: {(train_df['purchaseValue'] == 0).sum():,} ({(train_df['purchaseValue'] == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"1. This is a highly imbalanced regression problem with many zero purchase values\")\n",
    "print(\"2. Mix of numerical and categorical features from web analytics\")\n",
    "print(\"3. Some features have missing values that need handling\")\n",
    "print(\"4. Geographic, device, and traffic source features may be important predictors\")\n",
    "\n",
    "print(\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Handle missing values appropriately\")\n",
    "print(\"2. Encode categorical variables\")\n",
    "print(\"3. Consider feature engineering for web analytics data\")\n",
    "print(\"4. Try different models suitable for imbalanced regression\")\n",
    "print(\"5. Use appropriate evaluation metrics for imbalanced data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}